//! Demonstration of the new streaming ResultSet::Select implementation
//! 
//! This example shows how the ResultSet::Select variant now uses a streaming
//! iterator instead of materializing all rows upfront, providing significant
//! memory efficiency improvements for large result sets.

use tegdb::{Database, Result};
use std::time::Instant;

fn main() -> Result<()> {
    println!("=== Streaming ResultSet::Select Demo ===\n");

    // Create test database
    let mut db = Database::open("streaming_resultset_demo.db")?;

    // Create test table
    println!("1. Setting up test data...");
    db.execute("CREATE TABLE measurements (id INTEGER PRIMARY KEY, sensor_id INTEGER, timestamp INTEGER, value REAL)")?;

    // Insert a substantial amount of test data
    let start = Instant::now();
    for i in 1..=1000 {
        let sensor_id = (i % 50) + 1; // 50 different sensors
        let timestamp = 1640995200 + (i * 60); // One reading per minute
        let value = 20.0 + (i as f64 % 30.0); // Temperature readings 20-50Â°C
        
        db.execute(&format!(
            "INSERT INTO measurements (id, sensor_id, timestamp, value) VALUES ({i}, {sensor_id}, {timestamp}, {value})"
        ))?;
    }
    let insert_time = start.elapsed();
    println!("   âœ“ Inserted 1,000 rows in {:?}\n", insert_time);

    // Demonstrate streaming behavior with the new ResultSet::Select
    println!("2. Testing streaming ResultSet::Select behavior...\n");

    // Example 1: Process rows one by one using the iterator
    println!("--- Example 1: Processing rows one-by-one (streaming) ---");
    let start = Instant::now();
    let query_result = db.query("SELECT * FROM measurements WHERE sensor_id <= 5")?;
    println!("   âœ“ Query created in {:?} (no rows materialized yet)", start.elapsed());
    
    let start = Instant::now();
    let mut count = 0;
    for (i, row_result) in query_result.enumerate() {
        let _row = row_result?;
        count += 1;
        
        // Show streaming in action - process only first 3 rows
        if i < 3 {
            println!("   â€¢ Processing row {}: sensor_id={:?}, value={:?}", 
                     i + 1, _row.get(1), _row.get(3));
        }
        
        // Early termination example
        if count >= 5 {
            println!("   â€¢ Early termination after 5 rows");
            break;
        }
    }
    let process_time = start.elapsed();
    println!("   âœ“ Processed {} rows in {:?} (streaming)\n", count, process_time);

    // Example 2: Collect all rows for backward compatibility
    println!("--- Example 2: Backward compatibility (collect all rows) ---");
    let start = Instant::now();
    let query_result = db.query("SELECT id, sensor_id, value FROM measurements WHERE value > 45.0")?;
    let all_rows: Result<Vec<_>> = query_result.collect();
    let collect_time = start.elapsed();
    
    match all_rows {
        Ok(rows) => {
            println!("   âœ“ Collected {} rows in {:?}", rows.len(), collect_time);
            if let Some(first_row) = rows.first() {
                println!("   â€¢ First row: id={:?}, sensor_id={:?}, value={:?}", 
                         first_row.get(0), first_row.get(1), first_row.get(2));
            }
        }
        Err(e) => println!("   âœ— Error collecting rows: {}", e),
    }
    println!();

    // Example 3: Memory efficiency comparison
    println!("--- Example 3: Memory efficiency demonstration ---");
    
    // Show that we can process large result sets with constant memory
    println!("Processing all 1,000 rows with streaming (constant memory usage):");
    let start = Instant::now();
    let query_result = db.query("SELECT value FROM measurements")?;
    
    let mut sum = 0.0;
    let mut processed_count = 0;
    for row_result in query_result {
        let row = row_result?;
        if let Some(value) = row.get(0) {
            let numeric_value = match value {
                tegdb::SqlValue::Real(val) => *val,
                tegdb::SqlValue::Integer(val) => *val as f64,
                _ => continue,
            };
            sum += numeric_value;
            processed_count += 1;
        }
    }
    let streaming_time = start.elapsed();
    
    let average = sum / processed_count as f64;
    println!("   âœ“ Processed {} rows in {:?}", processed_count, streaming_time);
    println!("   âœ“ Average temperature: {:.2}Â°C", average);
    println!("   âœ“ Memory usage: O(1) - only one row in memory at a time");
    println!();

    // Example 4: LIMIT optimization
    println!("--- Example 4: LIMIT optimization (early termination) ---");
    let start = Instant::now();
    let query_result = db.query("SELECT * FROM measurements ORDER BY id LIMIT 10")?;
    let limited_rows: Result<Vec<_>> = query_result.collect();
    let limit_time = start.elapsed();
    
    match limited_rows {
        Ok(rows) => {
            println!("   âœ“ Retrieved {} rows with LIMIT 10 in {:?}", rows.len(), limit_time);
            println!("   âœ“ Streaming implementation stopped after 10 rows (no unnecessary work)");
        }
        Err(e) => println!("   âœ— Error: {}", e),
    }
    println!();

    // Summary
    println!("=== Summary ===");
    println!("ðŸš€ ResultSet::Select now uses streaming implementation:");
    println!("   â€¢ Memory efficient: O(1) memory usage instead of O(n)");
    println!("   â€¢ Early termination: LIMIT and WHERE clauses can stop processing early");
    println!("   â€¢ Lazy evaluation: Rows are processed only when consumed");
    println!("   â€¢ Backward compatible: Can still collect() to Vec when needed");
    println!("   â€¢ Better performance: No upfront materialization cost");
    println!();
    
    println!("ðŸ”§ Usage patterns:");
    println!("   â€¢ Use iterator methods for streaming: for row in result {{ ... }}");
    println!("   â€¢ Use .collect() for Vec<Vec<SqlValue>> when all rows needed");
    println!("   â€¢ Use .take(n) for processing only first N rows");
    println!("   â€¢ Use .filter() for additional row filtering");
    println!();
    
    println!("âœ… The streaming ResultSet::Select is now ready for production use!");

    // Cleanup
    std::fs::remove_file("streaming_resultset_demo.db").ok();

    Ok(())
}
