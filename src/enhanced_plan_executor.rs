//! Enhanced plan executor with configurable storage format support
//! 
//! This module provides an executor that can work with different row storage formats
//! including both the legacy HashMap format and the new native binary format.

use crate::planner::{ExecutionPlan, Assignment};
use crate::executor::{Executor, ResultSet, TableSchema};
use crate::parser::{SqlValue, Condition};
use crate::storage_format::{StorageFormat, evaluate_condition_on_row};
use crate::{Result, Error};
use std::collections::HashMap;

/// Enhanced plan executor with configurable storage format
pub struct EnhancedPlanExecutor<'a> {
    /// The underlying SQL executor
    executor: Executor<'a>,
    /// Table schemas for plan execution
    table_schemas: HashMap<String, TableSchema>,
    /// Storage format configuration
    storage_format: StorageFormat,
}

impl<'a> EnhancedPlanExecutor<'a> {
    /// Create a new enhanced plan executor
    pub fn new(
        transaction: crate::engine::Transaction<'a>,
        table_schemas: HashMap<String, TableSchema>,
        storage_format: StorageFormat
    ) -> Self {
        Self {
            executor: Executor::new_with_schemas(transaction, table_schemas.clone()),
            table_schemas,
            storage_format,
        }
    }

    /// Execute a plan generated by the query planner
    pub fn execute_plan(&mut self, plan: ExecutionPlan) -> Result<ResultSet> {
        match plan {
            ExecutionPlan::PrimaryKeyLookup { 
                table, 
                pk_values, 
                selected_columns, 
                additional_filter 
            } => {
                self.execute_primary_key_lookup(&table, &pk_values, &selected_columns, additional_filter.as_ref())
            }
            ExecutionPlan::IndexScan { 
                table, 
                index_name: _, // Not implemented yet
                key_conditions: _, 
                selected_columns, 
                filter, 
                limit: _ 
            } => {
                // Fall back to table scan for now
                self.execute_table_scan_optimized(&table, &selected_columns, filter.as_ref(), None, false)
            }
            ExecutionPlan::TableScan { 
                table, 
                selected_columns, 
                filter, 
                limit, 
                early_termination 
            } => {
                self.execute_table_scan_optimized(&table, &selected_columns, filter.as_ref(), limit, early_termination)
            }
            ExecutionPlan::Insert { 
                table, 
                rows, 
                conflict_resolution: _ // Not implemented yet
            } => {
                self.execute_insert_plan(&table, &rows)
            }
            ExecutionPlan::Update { 
                table, 
                assignments, 
                scan_plan 
            } => {
                self.execute_update_plan(&table, &assignments, *scan_plan)
            }
            ExecutionPlan::Delete { 
                table, 
                scan_plan 
            } => {
                self.execute_delete_plan(&table, *scan_plan)
            }
            ExecutionPlan::CreateTable { 
                table, 
                schema 
            } => {
                self.execute_create_table_plan(&table, &schema)
            }
            ExecutionPlan::DropTable { 
                table, 
                if_exists 
            } => {
                self.execute_drop_table_plan(&table, if_exists)
            }
            ExecutionPlan::Begin => {
                self.executor.begin_transaction()
            }
            ExecutionPlan::Commit => {
                self.executor.commit_transaction()
            }
            ExecutionPlan::Rollback => {
                self.executor.rollback_transaction()
            }
        }
    }

    /// Execute a primary key lookup with optimized row format
    fn execute_primary_key_lookup(
        &mut self, 
        table: &str, 
        pk_values: &HashMap<String, SqlValue>,
        selected_columns: &[String],
        additional_filter: Option<&Condition>
    ) -> Result<ResultSet> {
        // Get the row by primary key
        if let Some(row_data) = self.get_row_by_primary_key_optimized(table, pk_values)? {
            // Apply additional filtering if present
            let matches = if let Some(filter) = additional_filter {
                evaluate_condition_on_row(filter, &row_data)
            } else {
                true
            };

            if matches {
                // Extract selected columns
                let mut result_row = Vec::with_capacity(selected_columns.len());
                for col in selected_columns {
                    result_row.push(row_data.get(col).cloned().unwrap_or(SqlValue::Null));
                }

                Ok(ResultSet::Select {
                    columns: selected_columns.to_vec(),
                    rows: vec![result_row],
                })
            } else {
                // Row didn't match additional filter
                Ok(ResultSet::Select {
                    columns: selected_columns.to_vec(),
                    rows: vec![],
                })
            }
        } else {
            // Primary key not found
            Ok(ResultSet::Select {
                columns: selected_columns.to_vec(),
                rows: vec![],
            })
        }
    }

    /// Execute an optimized table scan using the configured storage format
    fn execute_table_scan_optimized(
        &mut self,
        table: &str,
        selected_columns: &[String],
        filter: Option<&Condition>,
        limit: Option<u64>,
        early_termination: bool
    ) -> Result<ResultSet> {
        let table_key_prefix = format!("{}:", table);
        let start_key = table_key_prefix.as_bytes().to_vec();
        let end_key = format!("{}~", table).as_bytes().to_vec();
        
        // Get table schema
        let schema = self.table_schemas.get(table)
            .ok_or_else(|| Error::Other(format!("Table '{}' not found", table)))?;
        
        // Collect scan results to avoid borrow conflicts
        let scan_results = self.executor.transaction_mut().scan(start_key..end_key)?;
        let scan_results: Vec<_> = scan_results.collect();
        
        let mut result_rows = Vec::new();
        let mut processed_count = 0;
        let effective_limit = limit.unwrap_or(u64::MAX) as usize;
        
        // Pre-allocate result capacity for better performance
        if let Some(limit_val) = limit {
            result_rows.reserve(std::cmp::min(limit_val as usize, 1000));
        }
        
        // Process rows with the configured storage format
        for (key, value) in scan_results {
            // Early termination check BEFORE expensive operations
            if early_termination && processed_count >= effective_limit {
                break;
            }
            
            processed_count += 1;
            
            // Parse the key to extract row identifier
            let key_str = String::from_utf8_lossy(&key);
            if !key_str.starts_with(&table_key_prefix) {
                continue;
            }
            
            // Use the storage format to efficiently process the row
            let matches = if let Some(condition) = filter {
                // Use optimized condition matching for native format
                match self.storage_format.matches_condition(&value, schema, condition) {
                    Ok(result) => result,
                    Err(_) => false, // Skip rows with deserialization errors
                }
            } else {
                true
            };
            
            if matches {
                // Use optimized column extraction for native format
                let column_values = match self.storage_format.deserialize_columns(&value, schema, selected_columns) {
                    Ok(values) => values,
                    Err(_) => continue, // Skip rows with deserialization errors
                };
                
                result_rows.push(column_values);
                
                // Early termination after we've found enough matching rows
                if early_termination && result_rows.len() >= effective_limit {
                    break;
                }
            }
        }
        
        Ok(ResultSet::Select {
            columns: selected_columns.to_vec(),
            rows: result_rows,
        })
    }

    /// Get a row by primary key using optimized storage format
    fn get_row_by_primary_key_optimized(
        &mut self,
        table: &str,
        pk_values: &HashMap<String, SqlValue>
    ) -> Result<Option<HashMap<String, SqlValue>>> {
        // Build the primary key
        let mut key_parts = Vec::new();
        
        // Get schema to determine primary key columns
        let schema = self.table_schemas.get(table)
            .ok_or_else(|| Error::Other(format!("Table '{}' not found", table)))?;
        
        // Find primary key columns in order
        let mut pk_columns: Vec<_> = schema.columns.iter()
            .filter(|col| col.constraints.contains(&crate::parser::ColumnConstraint::PrimaryKey))
            .collect();
        pk_columns.sort_by(|a, b| a.name.cmp(&b.name)); // Ensure consistent ordering
        
        if pk_columns.is_empty() {
            return Err(Error::Other(format!("Table '{}' has no primary key", table)));
        }
        
        // Build key components
        for pk_col in &pk_columns {
            if let Some(value) = pk_values.get(&pk_col.name) {
                key_parts.push(self.value_to_key_string(value));
            } else {
                return Err(Error::Other(format!("Missing primary key value for column '{}'", pk_col.name)));
            }
        }
        
        let key = format!("{}:{}", table, key_parts.join(":"));
        
        // Get the row data
        if let Some(value) = self.executor.transaction_mut().get(key.as_bytes()) {
            // Use the storage format to deserialize the row
            match self.storage_format.deserialize_row(&value, schema) {
                Ok(row_data) => Ok(Some(row_data)),
                Err(_) => Ok(None), // Row exists but can't be deserialized
            }
        } else {
            Ok(None)
        }
    }

    /// Execute insert plan with optimized storage format
    fn execute_insert_plan(&mut self, table: &str, rows: &[HashMap<String, SqlValue>]) -> Result<ResultSet> {
        let mut affected_rows = 0;
        
        for row_data in rows {
            // Validate row data against schema
            self.validate_row_data(table, row_data)?;
            
            // Build primary key - get schema separately to avoid borrow conflicts
            let key = {
                let schema = self.table_schemas.get(table)
                    .ok_or_else(|| Error::Other(format!("Table '{}' not found", table)))?;
                self.build_primary_key(table, row_data, schema)?
            };
            
            // Check for primary key constraint violation
            if self.primary_key_exists(&key)? {
                return Err(Error::Other(format!(
                    "Primary key constraint violation: duplicate key in table '{}'", 
                    table
                )));
            }
            
            // Check UNIQUE constraints
            self.validate_unique_constraints(table, row_data, None)?;
            
            // Serialize using the configured storage format
            let serialized_data = {
                let schema = self.table_schemas.get(table)
                    .ok_or_else(|| Error::Other(format!("Table '{}' not found", table)))?;
                self.storage_format.serialize_row(row_data, schema)?
            };
            
            // Store the row
            self.executor.transaction_mut().set(key.as_bytes(), serialized_data)?;
            affected_rows += 1;
        }
        
        Ok(ResultSet::Insert { rows_affected: affected_rows })
    }

    /// Build primary key string for a row
    fn build_primary_key(
        &self,
        table: &str,
        row_data: &HashMap<String, SqlValue>,
        schema: &TableSchema
    ) -> Result<String> {
        // Find primary key columns
        let mut pk_columns: Vec<_> = schema.columns.iter()
            .filter(|col| col.constraints.contains(&crate::parser::ColumnConstraint::PrimaryKey))
            .collect();
        pk_columns.sort_by(|a, b| a.name.cmp(&b.name)); // Ensure consistent ordering
        
        if pk_columns.is_empty() {
            return Err(Error::Other(format!("Table '{}' has no primary key", table)));
        }
        
        let mut key_parts = Vec::new();
        for pk_col in &pk_columns {
            if let Some(value) = row_data.get(&pk_col.name) {
                key_parts.push(self.value_to_key_string(value));
            } else {
                return Err(Error::Other(format!("Missing primary key value for column '{}'", pk_col.name)));
            }
        }
        
        Ok(format!("{}:{}", table, key_parts.join(":")))
    }

    /// Convert SqlValue to string for key building
    fn value_to_key_string(&self, value: &SqlValue) -> String {
        match value {
            SqlValue::Integer(i) => i.to_string(),
            SqlValue::Real(r) => r.to_string(),
            SqlValue::Text(t) => t.clone(),
            SqlValue::Null => "NULL".to_string(),
        }
    }

    /// Execute update plan with configurable storage format
    fn execute_update_plan(&mut self, table: &str, assignments: &[Assignment], scan_plan: ExecutionPlan) -> Result<ResultSet> {
        // First, execute the scan plan to find rows to update
        let scan_result = self.execute_plan(scan_plan)?;
        
        match scan_result {
            ResultSet::Select { columns, rows } => {
                let mut rows_affected = 0;
                
                for row_values in rows {
                    // Reconstruct the full row data
                    let mut row_data = HashMap::new();
                    for (i, col_name) in columns.iter().enumerate() {
                        if let Some(value) = row_values.get(i) {
                            row_data.insert(col_name.clone(), value.clone());
                        }
                    }
                    
                    // Apply updates
                    let mut updated_row = row_data.clone();
                    for assignment in assignments {
                        updated_row.insert(assignment.column.clone(), assignment.value.clone());
                    }
                    
                    // Generate the original key - get schema separately to avoid borrow conflicts
                    let original_key = {
                        let schema = self.table_schemas.get(table)
                            .ok_or_else(|| Error::Other(format!("Table '{}' not found", table)))?;
                        self.build_primary_key(table, &row_data, schema)?
                    };
                    
                    // Validate the updated row data
                    self.validate_row_data(table, &updated_row)?;
                    
                    // Check UNIQUE constraints (excluding the current row)
                    let original_key_bytes = original_key.as_bytes();
                    self.validate_unique_constraints(table, &updated_row, Some(original_key_bytes))?;
                    
                    // Serialize and update using the configured storage format
                    let serialized_row = {
                        let schema = self.table_schemas.get(table)
                            .ok_or_else(|| Error::Other(format!("Table '{}' not found", table)))?;
                        self.storage_format.serialize_row(&updated_row, schema)?
                    };
                    self.executor.transaction_mut().set(original_key.as_bytes(), serialized_row)?;
                    rows_affected += 1;
                }
                
                Ok(ResultSet::Update { rows_affected })
            }
            _ => Err(Error::Other("Invalid scan result for update".to_string())),
        }
    }

    /// Execute delete plan with configurable storage format
    fn execute_delete_plan(&mut self, table: &str, scan_plan: ExecutionPlan) -> Result<ResultSet> {
        // First, execute the scan plan to find rows to delete
        let scan_result = self.execute_plan(scan_plan)?;
        
        match scan_result {
            ResultSet::Select { columns, rows } => {
                let mut rows_affected = 0;
                
                // Get table schema for key generation
                let schema = self.table_schemas.get(table)
                    .ok_or_else(|| Error::Other(format!("Table '{}' not found", table)))?;
                
                for row_values in rows {
                    // Reconstruct the full row data to generate key
                    let mut row_data = HashMap::new();
                    for (i, col_name) in columns.iter().enumerate() {
                        if let Some(value) = row_values.get(i) {
                            row_data.insert(col_name.clone(), value.clone());
                        }
                    }
                    
                    // Generate key and delete
                    let row_key = self.build_primary_key(table, &row_data, schema)?;
                    self.executor.transaction_mut().delete(row_key.as_bytes())?;
                    rows_affected += 1;
                }
                
                Ok(ResultSet::Delete { rows_affected })
            }
            _ => Err(Error::Other("Invalid scan result for delete".to_string())),
        }
    }

    /// Execute create table plan (delegate to basic executor)
    fn execute_create_table_plan(&mut self, table: &str, schema: &TableSchema) -> Result<ResultSet> {
        use crate::parser::{CreateTableStatement, ColumnDefinition};
        
        // Convert schema back to CreateTableStatement for the executor
        let create_stmt = CreateTableStatement {
            table: table.to_string(),
            columns: schema.columns.iter().map(|col| ColumnDefinition {
                name: col.name.clone(),
                data_type: col.data_type.clone(),
                constraints: col.constraints.clone(),
            }).collect(),
        };
        
        self.executor.execute_create_table(create_stmt)
    }

    /// Execute drop table plan (delegate to basic executor)
    fn execute_drop_table_plan(&mut self, table: &str, if_exists: bool) -> Result<ResultSet> {
        use crate::parser::DropTableStatement;
        
        let drop_stmt = DropTableStatement {
            table: table.to_string(),
            if_exists,
        };
        
        self.executor.execute_drop_table(drop_stmt)
    }

    /// Validate row data against table schema
    fn validate_row_data(&self, table: &str, row_data: &HashMap<String, SqlValue>) -> Result<()> {
        let schema = self.table_schemas.get(table)
            .ok_or_else(|| crate::Error::Other(format!("Table '{}' not found", table)))?;
        
        // Check for required columns and data type compatibility
        for column in &schema.columns {
            if let Some(value) = row_data.get(&column.name) {
                // Validate data type compatibility
                self.validate_data_type(value, &column.data_type, &column.name)?;
                
                // Check NOT NULL constraint
                if column.constraints.contains(&crate::parser::ColumnConstraint::NotNull) && *value == SqlValue::Null {
                    return Err(crate::Error::Other(format!(
                        "Column '{}' cannot be NULL", column.name
                    )));
                }
            } else {
                // Column is missing - check if it's required
                if column.constraints.contains(&crate::parser::ColumnConstraint::NotNull) ||
                   column.constraints.contains(&crate::parser::ColumnConstraint::PrimaryKey) {
                    return Err(crate::Error::Other(format!(
                        "Required column '{}' is missing", column.name
                    )));
                }
            }
        }
        
        // Check for unknown columns
        for column_name in row_data.keys() {
            if !schema.columns.iter().any(|col| col.name == *column_name) {
                return Err(crate::Error::Other(format!(
                    "Unknown column '{}' for table '{}'", column_name, table
                )));
            }
        }
        
        Ok(())
    }

    /// Validate that a value matches the expected data type
    fn validate_data_type(&self, value: &SqlValue, expected_type: &crate::parser::DataType, column_name: &str) -> Result<()> {
        use crate::parser::DataType;
        use SqlValue::*;
        
        let is_valid = match (value, expected_type) {
            (Null, _) => true, // NULL is valid for any type (NOT NULL constraint checked separately)
            (Integer(_), DataType::Integer) => true,
            (Text(_), DataType::Text) => true,
            (Real(_), DataType::Real) => true,
            // Allow implicit conversions
            (Integer(_), DataType::Real) => true, // Integer can be converted to Real
            (Integer(_), DataType::Text) => true, // Integer can be converted to Text
            (Real(_), DataType::Text) => true, // Real can be converted to Text
            // For BLOB, we'll accept any type since SqlValue doesn't have Blob variant yet
            (_, DataType::Blob) => true,
            _ => false,
        };
        
        if !is_valid {
            return Err(crate::Error::Other(format!(
                "Type mismatch for column '{}': expected {:?}, got {:?}", 
                column_name, expected_type, self.get_value_type(value)
            )));
        }
        
        Ok(())
    }
    
    /// Get the type name of a SqlValue for error messages
    fn get_value_type(&self, value: &SqlValue) -> &'static str {
        match value {
            SqlValue::Null => "NULL",
            SqlValue::Integer(_) => "INTEGER",
            SqlValue::Real(_) => "REAL", 
            SqlValue::Text(_) => "TEXT",
        }
    }

    /// Check if a primary key already exists in the table
    fn primary_key_exists(&mut self, key: &str) -> Result<bool> {
        let key_bytes = key.as_bytes().to_vec();
        Ok(self.executor.transaction_mut().get(&key_bytes).is_some())
    }

    /// Get primary key columns for a table
    fn get_primary_key_columns(&self, table_name: &str) -> Result<Vec<String>> {
        if let Some(schema) = self.table_schemas.get(table_name) {
            let pk_columns: Vec<String> = schema.columns
                .iter()
                .filter(|col| col.constraints.contains(&crate::parser::ColumnConstraint::PrimaryKey))
                .map(|col| col.name.clone())
                .collect();
            
            if pk_columns.is_empty() {
                Err(crate::Error::Other(format!(
                    "Table '{}' must have a primary key column", table_name
                )))
            } else {
                Ok(pk_columns)
            }
        } else {
            Err(crate::Error::Other(format!("Table '{}' not found", table_name)))
        }
    }

    /// Validate unique constraints for a row
    fn validate_unique_constraints(&mut self, table: &str, row_data: &HashMap<String, SqlValue>, exclude_key: Option<&[u8]>) -> Result<()> {
        let schema = self.table_schemas.get(table)
            .ok_or_else(|| crate::Error::Other(format!("Table '{}' not found", table)))?
            .clone(); // Clone to avoid borrow conflicts
        
        // Get columns with UNIQUE constraints
        let unique_columns: Vec<_> = schema.columns
            .iter()
            .filter(|col| col.constraints.contains(&crate::parser::ColumnConstraint::Unique))
            .collect();
        
        if unique_columns.is_empty() {
            return Ok(()); // No UNIQUE constraints to check
        }
        
        // Scan existing rows to check for duplicates
        let table_key_prefix = format!("{}:", table);
        let start_key = table_key_prefix.as_bytes().to_vec();
        let end_key = format!("{}~", table).as_bytes().to_vec();
        
        let scan_results = self.executor.transaction_mut().scan(start_key..end_key)?;
        let scan_results: Vec<_> = scan_results.collect(); // Collect to avoid borrow conflicts
        
        for (existing_key, existing_value) in scan_results {
            // Skip the row we're updating (if any)
            if let Some(exclude) = exclude_key {
                if existing_key == exclude {
                    continue;
                }
            }
            
            // Deserialize the existing row
            match self.storage_format.deserialize_row(&existing_value, &schema) {
                Ok(existing_row) => {
                    // Check each UNIQUE column
                    for unique_col in &unique_columns {
                        if let (Some(new_val), Some(existing_val)) = (
                            row_data.get(&unique_col.name),
                            existing_row.get(&unique_col.name)
                        ) {
                            if new_val != &SqlValue::Null && existing_val != &SqlValue::Null && new_val == existing_val {
                                return Err(crate::Error::Other(format!(
                                    "UNIQUE constraint violation: duplicate value for column '{}'", 
                                    unique_col.name
                                )));
                            }
                        }
                    }
                }
                Err(_) => {
                    // Skip rows that can't be deserialized (might be from old format or corrupted)
                    continue;
                }
            }
        }
        
        Ok(())
    }

    /// Get reference to the underlying executor
    pub fn executor(&self) -> &Executor<'a> {
        &self.executor
    }

    /// Get mutable reference to the underlying executor
    pub fn executor_mut(&mut self) -> &mut Executor<'a> {
        &mut self.executor
    }
}
