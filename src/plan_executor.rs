//! Plan executor that executes query plans generated by the planner
//! 
//! This module provides an executor that can take execution plans from the QueryPlanner
//! and execute them against a TegDB engine instance using transactions for ACID compliance.

use crate::planner::{ExecutionPlan, Assignment};
use crate::executor::{Executor, ResultSet, TableSchema};
use crate::parser::{SqlValue, Condition, ComparisonOperator};
use crate::optimized_serialization::OptimizedRowSerializer;
use crate::Result;
use std::collections::HashMap;

/// A plan executor that executes query plans generated by the planner
pub struct PlanExecutor<'a> {
    /// The underlying SQL executor
    executor: Executor<'a>,
    /// Table schemas for plan execution
    table_schemas: HashMap<String, TableSchema>,
}

impl<'a> PlanExecutor<'a> {
    /// Create a new plan executor
    pub fn new(
        transaction: crate::engine::Transaction<'a>,
        table_schemas: HashMap<String, TableSchema>
    ) -> Self {
        Self {
            executor: Executor::new_with_schemas(transaction, table_schemas.clone()),
            table_schemas,
        }
    }

    /// Execute a plan generated by the query planner
    pub fn execute_plan(&mut self, plan: ExecutionPlan) -> Result<ResultSet> {
        match plan {
            ExecutionPlan::PrimaryKeyLookup { 
                table, 
                pk_values, 
                selected_columns, 
                additional_filter 
            } => {
                self.execute_primary_key_lookup(&table, &pk_values, &selected_columns, additional_filter.as_ref())
            }
            ExecutionPlan::IndexScan { 
                table, 
                index_name: _, // Not implemented yet
                key_conditions: _, 
                selected_columns, 
                filter, 
                limit: _ 
            } => {
                // Fall back to table scan for now
                self.execute_table_scan_optimized(&table, &selected_columns, filter.as_ref(), None, false)
            }
            ExecutionPlan::TableScan { 
                table, 
                selected_columns, 
                filter, 
                limit, 
                early_termination 
            } => {
                self.execute_table_scan_optimized(&table, &selected_columns, filter.as_ref(), limit, early_termination)
            }
            ExecutionPlan::Insert { 
                table, 
                rows, 
                conflict_resolution: _ // Not implemented yet
            } => {
                self.execute_insert_plan(&table, &rows)
            }
            ExecutionPlan::Update { 
                table, 
                assignments, 
                scan_plan 
            } => {
                self.execute_update_plan(&table, &assignments, *scan_plan)
            }
            ExecutionPlan::Delete { 
                table: _, 
                scan_plan 
            } => {
                self.execute_delete_plan(*scan_plan)
            }
            ExecutionPlan::CreateTable { 
                table, 
                schema 
            } => {
                self.execute_create_table_plan(&table, &schema)
            }
            ExecutionPlan::DropTable { 
                table, 
                if_exists 
            } => {
                self.execute_drop_table_plan(&table, if_exists)
            }
            ExecutionPlan::Begin => {
                self.executor.begin_transaction()
            }
            ExecutionPlan::Commit => {
                self.executor.commit_transaction()
            }
            ExecutionPlan::Rollback => {
                self.executor.rollback_transaction()
            }
        }
    }

    /// Execute a primary key lookup (most efficient)
    fn execute_primary_key_lookup(
        &mut self, 
        table: &str, 
        pk_values: &HashMap<String, SqlValue>,
        selected_columns: &[String],
        additional_filter: Option<&Condition>
    ) -> Result<ResultSet> {
        // Get the row by primary key
        if let Some(row_data) = self.get_row_by_primary_key(table, pk_values)? {
            // Apply additional filtering if present
            let matches = if let Some(filter) = additional_filter {
                self.evaluate_condition(filter, &row_data)
            } else {
                true
            };

            if matches {
                // Extract selected columns
                let mut result_row = Vec::with_capacity(selected_columns.len());
                for col in selected_columns {
                    result_row.push(row_data.get(col).cloned().unwrap_or(SqlValue::Null));
                }

                Ok(ResultSet::Select {
                    columns: selected_columns.to_vec(),
                    rows: vec![result_row],
                })
            } else {
                // Row didn't match additional filter
                Ok(ResultSet::Select {
                    columns: selected_columns.to_vec(),
                    rows: vec![],
                })
            }
        } else {
            // Primary key not found
            Ok(ResultSet::Select {
                columns: selected_columns.to_vec(),
                rows: vec![],
            })
        }
    }

    /// Execute an optimized table scan with performance improvements
    fn execute_table_scan_optimized(
        &mut self,
        table: &str,
        selected_columns: &[String],
        filter: Option<&Condition>,
        limit: Option<u64>,
        early_termination: bool
    ) -> Result<ResultSet> {
        let table_key_prefix = format!("{}:", table);
        let start_key = table_key_prefix.as_bytes().to_vec();
        let end_key = format!("{}~", table).as_bytes().to_vec();
        
        // Collect scan results to avoid borrow conflicts
        let scan_results = self.executor.transaction_mut().scan(start_key..end_key)?;
        let scan_results: Vec<_> = scan_results.collect();
        
        let mut result_rows = Vec::new();
        let mut processed_count = 0;
        let effective_limit = limit.unwrap_or(u64::MAX) as usize;
        
        // Pre-allocate result capacity for better performance
        if let Some(limit_val) = limit {
            result_rows.reserve(std::cmp::min(limit_val as usize, 1000));
        }
        
        // Process rows with minimal overhead
        for (key, value) in scan_results {
            // Early termination check BEFORE expensive operations
            if early_termination && processed_count >= effective_limit {
                break;
            }
            
            // Use existing but optimized row processing
            if let Ok(row_data) = self.deserialize_row(table, &key, &value) {
                // Apply filter if present
                let matches = if let Some(condition) = filter {
                    self.evaluate_condition(condition, &row_data)
                } else {
                    true
                };
                
                if matches {
                    // Extract selected columns with pre-allocated vector
                    let mut result_row = Vec::with_capacity(selected_columns.len());
                    for col in selected_columns {
                        result_row.push(row_data.get(col).cloned().unwrap_or(SqlValue::Null));
                    }
                    result_rows.push(result_row);
                    processed_count += 1;
                    
                    // Break early if we've reached the limit
                    if processed_count >= effective_limit {
                        break;
                    }
                }
            }
        }

        Ok(ResultSet::Select {
            columns: selected_columns.to_vec(),
            rows: result_rows,
        })
    }

    /// Execute an insert plan
    fn execute_insert_plan(&mut self, table: &str, rows: &[HashMap<String, SqlValue>]) -> Result<ResultSet> {
        let mut rows_affected = 0;

        for row_data in rows {
            // Validate row data against schema
            self.validate_row_data(table, row_data)?;

            // Generate row key based on primary key values
            let row_key = self.generate_row_key(table, row_data)?;
            
            // Check for primary key constraint violation
            if self.primary_key_exists(table, row_data)? {
                return Err(crate::Error::Other(format!(
                    "Primary key constraint violation: duplicate key in table '{}'", 
                    table
                )));
            }

            // Check UNIQUE constraints
            self.validate_unique_constraints(table, row_data, None)?;

            // Serialize the row and store
            let serialized_row = self.serialize_row(table, row_data)?;
            self.executor.transaction_mut().set(row_key.as_bytes(), serialized_row)?;
            rows_affected += 1;
        }

        Ok(ResultSet::Insert { rows_affected })
    }

    /// Execute an update plan
    fn execute_update_plan(
        &mut self, 
        table: &str, 
        assignments: &[Assignment], 
        scan_plan: ExecutionPlan
    ) -> Result<ResultSet> {
        // First, execute the scan plan to find rows to update
        let scan_result = self.execute_plan(scan_plan)?;
        
        match scan_result {
            ResultSet::Select { columns, rows } => {
                let mut rows_affected = 0;
                
                for row_values in rows {
                    // Reconstruct the full row data
                    let mut row_data = HashMap::new();
                    for (i, col_name) in columns.iter().enumerate() {
                        if let Some(value) = row_values.get(i) {
                            row_data.insert(col_name.clone(), value.clone());
                        }
                    }
                    
                    // Apply updates
                    let mut updated_row = row_data.clone();
                    for assignment in assignments {
                        updated_row.insert(assignment.column.clone(), assignment.value.clone());
                    }
                    
                    // Validate updated row
                    self.validate_row_data(table, &updated_row)?;
                    
                    // Generate the original key and update
                    let original_key = self.generate_row_key(table, &row_data)?;
                    
                    // Check UNIQUE constraints (excluding current row)
                    self.validate_unique_constraints(table, &updated_row, Some(original_key.as_bytes()))?;
                    
                    // Serialize and update
                    let serialized_row = self.serialize_row(table, &updated_row)?;
                    self.executor.transaction_mut().set(original_key.as_bytes(), serialized_row)?;
                    rows_affected += 1;
                }
                
                Ok(ResultSet::Update { rows_affected })
            }
            _ => Err(crate::Error::Other("Invalid scan result for update".to_string())),
        }
    }

    /// Execute a delete plan
    fn execute_delete_plan(&mut self, scan_plan: ExecutionPlan) -> Result<ResultSet> {
        // Get table name before moving scan_plan
        let table_name = scan_plan.primary_table().unwrap_or("unknown").to_string();
        
        // First, execute the scan plan to find rows to delete
        let scan_result = self.execute_plan(scan_plan)?;
        
        match scan_result {
            ResultSet::Select { columns, rows } => {
                let mut rows_affected = 0;
                
                for row_values in rows {
                    // Reconstruct the row data to get the primary key
                    let mut row_data = HashMap::new();
                    for (i, col_name) in columns.iter().enumerate() {
                        if let Some(value) = row_values.get(i) {
                            row_data.insert(col_name.clone(), value.clone());
                        }
                    }
                    
                    // Generate the key and delete
                    let row_key = self.generate_row_key(&table_name, &row_data)?;
                    self.executor.transaction_mut().delete(row_key.as_bytes())?;
                    rows_affected += 1;
                }
                
                Ok(ResultSet::Delete { rows_affected })
            }
            _ => Err(crate::Error::Other("Invalid scan result for delete".to_string())),
        }
    }

    /// Execute a create table plan
    fn execute_create_table_plan(&mut self, table: &str, schema: &TableSchema) -> Result<ResultSet> {
        // Convert back to CreateTableStatement for the existing executor
        let create_statement = crate::parser::CreateTableStatement {
            table: table.to_string(),
            columns: schema.columns.iter().map(|col| crate::parser::ColumnDefinition {
                name: col.name.clone(),
                data_type: col.data_type.clone(),
                constraints: col.constraints.clone(),
            }).collect(),
        };
        
        self.executor.execute_create_table(create_statement)
    }

    /// Execute a drop table plan
    fn execute_drop_table_plan(&mut self, table: &str, if_exists: bool) -> Result<ResultSet> {
        let drop_statement = crate::parser::DropTableStatement {
            table: table.to_string(),
            if_exists,
        };
        
        self.executor.execute_drop_table(drop_statement)
    }

    /// Optimized deserialization that only extracts needed columns
    fn deserialize_selected_columns_optimized(
        &self,
        table: &str,
        key: &[u8],
        value: &[u8],
        selected_columns: &[String],
        filter: Option<&Condition>,
        _schema: &TableSchema
    ) -> Result<Option<Vec<SqlValue>>> {
        // Step 1: Extract primary key values from the key
        let pk_data = self.extract_pk_values_from_key(table, key)?;
        
        // Step 2: Use optimized deserializer to get only needed columns
        let mut column_names_needed = selected_columns.to_vec();
        
        // If we have a filter, we might need additional columns for evaluation
        if let Some(condition) = filter {
            let filter_columns = self.extract_condition_columns(condition);
            for col in filter_columns {
                if !column_names_needed.contains(&col) {
                    column_names_needed.push(col);
                }
            }
        }
        
        // Use optimized deserialization for stored (non-PK) columns
        let stored_data = OptimizedRowSerializer::deserialize_columns_only(value, &column_names_needed)?;
        
        // Combine PK and stored data
        let mut full_row_data = pk_data;
        full_row_data.extend(stored_data);
        
        // Apply filter if present
        let matches = if let Some(condition) = filter {
            self.evaluate_condition(condition, &full_row_data)
        } else {
            true
        };
        
        if matches {
            // Extract only the originally requested columns
            let mut result_row = Vec::with_capacity(selected_columns.len());
            for col in selected_columns {
                result_row.push(full_row_data.get(col).cloned().unwrap_or(SqlValue::Null));
            }
            Ok(Some(result_row))
        } else {
            Ok(None)
        }
    }
    
    /// Extract primary key values from the row key
    fn extract_pk_values_from_key(&self, table: &str, key: &[u8]) -> Result<HashMap<String, SqlValue>> {
        let mut pk_data = HashMap::new();
        
        let key_str = std::str::from_utf8(key)
            .map_err(|e| crate::Error::Other(format!("Invalid key encoding: {}", e)))?;
        
        if let Some(key_suffix) = key_str.strip_prefix(&format!("{}:", table)) {
            let pk_columns = self.get_primary_key_columns(table)?;
            let pk_values_str: Vec<&str> = key_suffix.split(':').collect();
            
            if pk_values_str.len() == pk_columns.len() {
                for (pk_col, pk_value_str) in pk_columns.iter().zip(pk_values_str.iter()) {
                    let parsed_value = self.parse_pk_value(table, pk_col, pk_value_str)?;
                    pk_data.insert(pk_col.clone(), parsed_value);
                }
            }
        }
        
        Ok(pk_data)
    }
    
    /// Extract column names referenced in a condition
    fn extract_condition_columns(&self, condition: &Condition) -> Vec<String> {
        let mut columns = Vec::new();
        self.collect_condition_columns(condition, &mut columns);
        columns.sort();
        columns.dedup();
        columns
    }
    
    /// Recursively collect column names from a condition
    fn collect_condition_columns(&self, condition: &Condition, columns: &mut Vec<String>) {
        match condition {
            Condition::Comparison { left, .. } => {
                columns.push(left.clone());
            }
            Condition::And(left, right) | Condition::Or(left, right) => {
                self.collect_condition_columns(left, columns);
                self.collect_condition_columns(right, columns);
            }
        }
    }

    // Helper methods that delegate to the underlying executor
    fn get_row_by_primary_key(&mut self, table: &str, pk_values: &HashMap<String, SqlValue>) -> Result<Option<HashMap<String, SqlValue>>> {
        let row_key = self.generate_row_key(table, pk_values)?;
        
        if let Some(value) = self.executor.transaction_mut().get(row_key.as_bytes()) {
            Ok(Some(self.deserialize_row(table, row_key.as_bytes(), &value)?))
        } else {
            Ok(None)
        }
    }

    fn evaluate_condition(&self, condition: &Condition, row_data: &HashMap<String, SqlValue>) -> bool {
        match condition {
            Condition::Comparison { left, operator, right } => {
                if let Some(left_value) = row_data.get(left) {
                    self.compare_values(left_value, operator, right)
                } else {
                    false
                }
            }
            Condition::And(left, right) => {
                self.evaluate_condition(left, row_data) && self.evaluate_condition(right, row_data)
            }
            Condition::Or(left, right) => {
                self.evaluate_condition(left, row_data) || self.evaluate_condition(right, row_data)
            }
        }
    }

    fn compare_values(&self, left: &SqlValue, operator: &ComparisonOperator, right: &SqlValue) -> bool {
        use ComparisonOperator::*;
        
        match (left, right) {
            (SqlValue::Integer(l), SqlValue::Integer(r)) => match operator {
                Equal => l == r,
                NotEqual => l != r,
                LessThan => l < r,
                LessThanOrEqual => l <= r,
                GreaterThan => l > r,
                GreaterThanOrEqual => l >= r,
                Like => false,
            },
            (SqlValue::Real(l), SqlValue::Real(r)) => match operator {
                Equal => (l - r).abs() < f64::EPSILON,
                NotEqual => (l - r).abs() >= f64::EPSILON,
                LessThan => l < r,
                LessThanOrEqual => l <= r,
                GreaterThan => l > r,
                GreaterThanOrEqual => l >= r,
                Like => false,
            },
            (SqlValue::Text(l), SqlValue::Text(r)) => match operator {
                Equal => l == r,
                NotEqual => l != r,
                LessThan => l < r,
                LessThanOrEqual => l <= r,
                GreaterThan => l > r,
                GreaterThanOrEqual => l >= r,
                Like => l.contains(r),
            },
            (SqlValue::Null, SqlValue::Null) => match operator {
                Equal => true,
                NotEqual => false,
                _ => false,
            },
            _ => false,
        }
    }

    // Delegate remaining methods to the underlying executor
    fn serialize_row(&self, table: &str, row_data: &HashMap<String, SqlValue>) -> Result<Vec<u8>> {
        // Access the executor's private method through the public interface
        // This is a bit hacky but avoids code duplication
        let pk_columns = self.get_primary_key_columns(table)?;
        
        let mut non_pk_data = HashMap::new();
        for (col_name, value) in row_data {
            if !pk_columns.contains(col_name) {
                non_pk_data.insert(col_name.clone(), value.clone());
            }
        }
        
        Ok(crate::serialization::BinaryRowSerializer::serialize(&non_pk_data))
    }

    fn deserialize_row(&self, table: &str, key: &[u8], data: &[u8]) -> Result<HashMap<String, SqlValue>> {
        let mut row_data = crate::serialization::BinaryRowSerializer::deserialize(data)?;
        
        let key_str = std::str::from_utf8(key)
            .map_err(|e| crate::Error::Other(format!("Invalid key encoding: {}", e)))?;
        
        if let Some(key_suffix) = key_str.strip_prefix(&format!("{}:", table)) {
            let pk_columns = self.get_primary_key_columns(table)?;
            let pk_values_str: Vec<&str> = key_suffix.split(':').collect();
            
            if pk_values_str.len() != pk_columns.len() {
                return Err(crate::Error::Other(format!(
                    "Key format mismatch: expected {} PK values, got {}", 
                    pk_columns.len(), pk_values_str.len()
                )));
            }
            
            // Get schema info (we'll need to access this from the executor)
            for (pk_col, pk_value_str) in pk_columns.iter().zip(pk_values_str.iter()) {
                let parsed_value = self.parse_pk_value(table, pk_col, pk_value_str)?;
                row_data.insert(pk_col.clone(), parsed_value);
            }
        }
        
        Ok(row_data)
    }

    fn parse_pk_value(&self, table: &str, column: &str, value_str: &str) -> Result<SqlValue> {
        // Get column data type from schema
        if let Some(schema) = self.table_schemas.get(table) {
            if let Some(col_info) = schema.columns.iter().find(|col| col.name == column) {
                match col_info.data_type {
                    crate::parser::DataType::Integer => {
                        // Remove zero padding and parse
                        let cleaned = value_str.trim_start_matches('0');
                        let cleaned = if cleaned.is_empty() { "0" } else { cleaned };
                        Ok(SqlValue::Integer(cleaned.parse::<i64>()
                            .map_err(|e| crate::Error::Other(format!("Failed to parse integer PK value '{}': {}", value_str, e)))?))
                    },
                    crate::parser::DataType::Text => {
                        Ok(SqlValue::Text(value_str.to_string()))
                    },
                    crate::parser::DataType::Real => {
                        Ok(SqlValue::Real(value_str.parse::<f64>()
                            .map_err(|e| crate::Error::Other(format!("Failed to parse real PK value '{}': {}", value_str, e)))?))
                    },
                    crate::parser::DataType::Blob => {
                        // For now, treat BLOB as text in primary keys
                        Ok(SqlValue::Text(value_str.to_string()))
                    },
                }
            } else {
                Err(crate::Error::Other(format!("Column '{}' not found in table '{}'", column, table)))
            }
        } else {
            Err(crate::Error::Other(format!("Table '{}' not found", table)))
        }
    }

    fn validate_row_data(&self, table: &str, row_data: &HashMap<String, SqlValue>) -> Result<()> {
        let schema = self.table_schemas.get(table)
            .ok_or_else(|| crate::Error::Other(format!("Table '{}' not found", table)))?;
        
        // Check for required columns and data type compatibility
        for column in &schema.columns {
            if let Some(value) = row_data.get(&column.name) {
                // Validate data type compatibility
                self.validate_data_type(value, &column.data_type, &column.name)?;
                
                // Check NOT NULL constraint
                if column.constraints.contains(&crate::parser::ColumnConstraint::NotNull) && *value == SqlValue::Null {
                    return Err(crate::Error::Other(format!(
                        "Column '{}' cannot be NULL", column.name
                    )));
                }
            } else {
                // Column is missing - check if it's required
                if column.constraints.contains(&crate::parser::ColumnConstraint::NotNull) ||
                   column.constraints.contains(&crate::parser::ColumnConstraint::PrimaryKey) {
                    return Err(crate::Error::Other(format!(
                        "Required column '{}' is missing", column.name
                    )));
                }
            }
        }
        
        // Check for unknown columns
        for column_name in row_data.keys() {
            if !schema.columns.iter().any(|col| col.name == *column_name) {
                return Err(crate::Error::Other(format!(
                    "Unknown column '{}' for table '{}'", column_name, table
                )));
            }
        }
        
        Ok(())
    }

    /// Validate that a value matches the expected data type
    fn validate_data_type(&self, value: &SqlValue, expected_type: &crate::parser::DataType, column_name: &str) -> Result<()> {
        use crate::parser::DataType;
        use SqlValue::*;
        
        let is_valid = match (value, expected_type) {
            (Null, _) => true, // NULL is valid for any type (NOT NULL constraint checked separately)
            (Integer(_), DataType::Integer) => true,
            (Text(_), DataType::Text) => true,
            (Real(_), DataType::Real) => true,
            // Allow implicit conversions
            (Integer(_), DataType::Real) => true, // Integer can be converted to Real
            (Integer(_), DataType::Text) => true, // Integer can be converted to Text
            (Real(_), DataType::Text) => true, // Real can be converted to Text
            // For BLOB, we'll accept any type since SqlValue doesn't have Blob variant yet
            (_, DataType::Blob) => true,
            _ => false,
        };
        
        if !is_valid {
            return Err(crate::Error::Other(format!(
                "Type mismatch for column '{}': expected {:?}, got {:?}", 
                column_name, expected_type, self.get_value_type(value)
            )));
        }
        
        Ok(())
    }
    
    /// Get the type name of a SqlValue for error messages
    fn get_value_type(&self, value: &SqlValue) -> &'static str {
        match value {
            SqlValue::Null => "NULL",
            SqlValue::Integer(_) => "INTEGER",
            SqlValue::Real(_) => "REAL", 
            SqlValue::Text(_) => "TEXT",
        }
    }

    fn generate_row_key(&self, table: &str, row_data: &HashMap<String, SqlValue>) -> Result<String> {
        let pk_columns = self.get_primary_key_columns(table)?;
        
        let pk_values: Result<Vec<String>> = pk_columns
            .iter()
            .map(|col| {
                match row_data.get(col) {
                    Some(SqlValue::Integer(i)) => Ok(format!("{:020}", i)),
                    Some(SqlValue::Text(s)) => Ok(s.clone()),
                    Some(SqlValue::Real(r)) => Ok(format!("{:020.10}", r)),
                    Some(SqlValue::Null) => Err(crate::Error::Other(format!(
                        "Primary key column '{}' cannot be NULL", col
                    ))),
                    None => Err(crate::Error::Other(format!(
                        "Primary key column '{}' is required", col
                    ))),
                }
            })
            .collect();

        let pk_values = pk_values?;
        Ok(format!("{}:{}", table, pk_values.join(":")))
    }

    fn primary_key_exists(&mut self, table: &str, row_data: &HashMap<String, SqlValue>) -> Result<bool> {
        let row_key = self.generate_row_key(table, row_data)?;
        let key_bytes = row_key.as_bytes().to_vec();
        Ok(self.executor.transaction_mut().get(&key_bytes).is_some())
    }

    fn get_primary_key_columns(&self, table_name: &str) -> Result<Vec<String>> {
        if let Some(schema) = self.table_schemas.get(table_name) {
            let pk_columns: Vec<String> = schema.columns
                .iter()
                .filter(|col| col.constraints.contains(&crate::parser::ColumnConstraint::PrimaryKey))
                .map(|col| col.name.clone())
                .collect();
            
            if pk_columns.is_empty() {
                Err(crate::Error::Other(format!(
                    "Table '{}' must have a primary key column", table_name
                )))
            } else {
                Ok(pk_columns)
            }
        } else {
            Err(crate::Error::Other(format!("Table '{}' not found", table_name)))
        }
    }

    fn validate_unique_constraints(&mut self, table: &str, row_data: &HashMap<String, SqlValue>, exclude_key: Option<&[u8]>) -> Result<()> {
        let schema = self.table_schemas.get(table)
            .ok_or_else(|| crate::Error::Other(format!("Table '{}' not found", table)))?;
        
        // Get columns with UNIQUE constraints
        let unique_columns: Vec<_> = schema.columns
            .iter()
            .filter(|col| col.constraints.contains(&crate::parser::ColumnConstraint::Unique))
            .collect();
        
        if unique_columns.is_empty() {
            return Ok(()); // No UNIQUE constraints to check
        }
        
        // Scan existing rows to check for duplicates
        let table_key_prefix = format!("{}:", table);
        let start_key = table_key_prefix.as_bytes().to_vec();
        let end_key = format!("{}~", table).as_bytes().to_vec();
        
        let scan_results = self.executor.transaction_mut().scan(start_key..end_key)?;
        let scan_results: Vec<_> = scan_results.collect(); // Collect to avoid borrow conflicts
        
        for (existing_key, existing_value) in scan_results {
            // Skip the row we're updating (if any)
            if let Some(exclude) = exclude_key {
                if existing_key == exclude {
                    continue;
                }
            }
            
            if let Ok(existing_row) = self.deserialize_row(table, &existing_key, &existing_value) {
                // Check each UNIQUE column
                for unique_col in &unique_columns {
                    if let (Some(new_val), Some(existing_val)) = (
                        row_data.get(&unique_col.name),
                        existing_row.get(&unique_col.name)
                    ) {
                        if new_val != &SqlValue::Null && existing_val != &SqlValue::Null && new_val == existing_val {
                            return Err(crate::Error::Other(format!(
                                "UNIQUE constraint violation: duplicate value for column '{}'", 
                                unique_col.name
                            )));
                        }
                    }
                }
            }
        }
        
        Ok(())
    }

    /// Get access to the underlying executor for backward compatibility
    pub fn executor(&self) -> &Executor<'a> {
        &self.executor
    }

    /// Get mutable access to the underlying executor
    pub fn executor_mut(&mut self) -> &mut Executor<'a> {
        &mut self.executor
    }
}
